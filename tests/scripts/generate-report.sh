#!/bin/bash

# ALEX æµ‹è¯•æŠ¥å‘Šç”Ÿæˆè„šæœ¬
# é›†æˆæ‰€æœ‰æµ‹è¯•ç»“æœå¹¶ç”Ÿæˆç»¼åˆæŠ¥å‘Š

set -e

# è„šæœ¬ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
TESTS_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# é»˜è®¤é…ç½®
DEFAULT_OUTPUT_DIR="$TESTS_ROOT/reports"
DEFAULT_FORMAT="all"
DEFAULT_TEMPLATE="default"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_header() {
    echo -e "${PURPLE}================================${NC}"
    echo -e "${PURPLE} $1 ${NC}"
    echo -e "${PURPLE}================================${NC}"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
ALEX æµ‹è¯•æŠ¥å‘Šç”Ÿæˆè„šæœ¬

ç”¨æ³•: $0 [OPTIONS]

é€‰é¡¹:
  -o, --output DIR           è¾“å‡ºç›®å½• (é»˜è®¤: $DEFAULT_OUTPUT_DIR)
  -f, --format FORMAT        æŠ¥å‘Šæ ¼å¼: html, json, markdown, csv, all (é»˜è®¤: $DEFAULT_FORMAT)
  -t, --template TEMPLATE    æŠ¥å‘Šæ¨¡æ¿: default, minimal, detailed (é»˜è®¤: $DEFAULT_TEMPLATE)
  -i, --input DIR            è¾“å…¥ç›®å½•ï¼ŒåŒ…å«æµ‹è¯•ç»“æœ
  -c, --compare BASELINE     ä¸åŸºå‡†æŠ¥å‘Šå¯¹æ¯”
  -s, --summary-only         ä»…ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
  --include-performance      åŒ…å«æ€§èƒ½æµ‹è¯•ç»“æœ
  --include-coverage         åŒ…å«è¦†ç›–ç‡æŠ¥å‘Š
  --include-acceptance       åŒ…å«éªŒæ”¶æµ‹è¯•ç»“æœ
  --send-email EMAIL         å‘é€æŠ¥å‘Šåˆ°æŒ‡å®šé‚®ç®±
  --upload-s3 BUCKET         ä¸Šä¼ æŠ¥å‘Šåˆ°S3
  --webhook URL              å‘é€æŠ¥å‘Šåˆ°webhook
  -h, --help                 æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

æŠ¥å‘Šæ ¼å¼:
  html                       ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š
  json                       ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š
  markdown                   ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š
  csv                        ç”ŸæˆCSVæ•°æ®æ–‡ä»¶
  all                        ç”Ÿæˆæ‰€æœ‰æ ¼å¼æŠ¥å‘Š

æ¨¡æ¿é€‰é¡¹:
  default                    æ ‡å‡†æŠ¥å‘Šæ¨¡æ¿
  minimal                    ç®€åŒ–æŠ¥å‘Šæ¨¡æ¿
  detailed                   è¯¦ç»†æŠ¥å‘Šæ¨¡æ¿
  executive                  é«˜ç®¡æ‘˜è¦æ¨¡æ¿

ç¯å¢ƒå˜é‡:
  ALEX_REPORT_OUTPUT_DIR     æŠ¥å‘Šè¾“å‡ºç›®å½•
  ALEX_REPORT_FORMAT         é»˜è®¤æŠ¥å‘Šæ ¼å¼
  ALEX_REPORT_TEMPLATE       é»˜è®¤æŠ¥å‘Šæ¨¡æ¿
  EMAIL_CONFIG               é‚®ä»¶é…ç½®æ–‡ä»¶è·¯å¾„
  S3_CONFIG                  S3é…ç½®æ–‡ä»¶è·¯å¾„

ç¤ºä¾‹:
  $0                         # ç”Ÿæˆæ‰€æœ‰æ ¼å¼çš„é»˜è®¤æŠ¥å‘Š
  $0 -f html -t detailed     # ç”Ÿæˆè¯¦ç»†çš„HTMLæŠ¥å‘Š
  $0 -o ./custom_reports     # è¾“å‡ºåˆ°è‡ªå®šä¹‰ç›®å½•
  $0 -c baseline.json        # ä¸åŸºå‡†å¯¹æ¯”
  $0 --send-email admin@example.com  # å‘é€é‚®ä»¶
  $0 --summary-only          # ä»…ç”Ÿæˆæ‘˜è¦

EOF
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
parse_args() {
    OUTPUT_DIR="${ALEX_REPORT_OUTPUT_DIR:-$DEFAULT_OUTPUT_DIR}"
    FORMAT="${ALEX_REPORT_FORMAT:-$DEFAULT_FORMAT}"
    TEMPLATE="${ALEX_REPORT_TEMPLATE:-$DEFAULT_TEMPLATE}"
    INPUT_DIR=""
    BASELINE_FILE=""
    SUMMARY_ONLY=false
    INCLUDE_PERFORMANCE=true
    INCLUDE_COVERAGE=true
    INCLUDE_ACCEPTANCE=true
    EMAIL_RECIPIENT=""
    S3_BUCKET=""
    WEBHOOK_URL=""

    while [[ $# -gt 0 ]]; do
        case $1 in
            -o|--output)
                OUTPUT_DIR="$2"
                shift 2
                ;;
            -f|--format)
                FORMAT="$2"
                shift 2
                ;;
            -t|--template)
                TEMPLATE="$2"
                shift 2
                ;;
            -i|--input)
                INPUT_DIR="$2"
                shift 2
                ;;
            -c|--compare)
                BASELINE_FILE="$2"
                shift 2
                ;;
            -s|--summary-only)
                SUMMARY_ONLY=true
                shift
                ;;
            --include-performance)
                INCLUDE_PERFORMANCE=true
                shift
                ;;
            --include-coverage)
                INCLUDE_COVERAGE=true
                shift
                ;;
            --include-acceptance)
                INCLUDE_ACCEPTANCE=true
                shift
                ;;
            --send-email)
                EMAIL_RECIPIENT="$2"
                shift 2
                ;;
            --upload-s3)
                S3_BUCKET="$2"
                shift 2
                ;;
            --webhook)
                WEBHOOK_URL="$2"
                shift 2
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

# éªŒè¯ç¯å¢ƒå’Œä¾èµ–
validate_environment() {
    log_info "éªŒè¯ç¯å¢ƒå’Œä¾èµ–..."

    # æ£€æŸ¥å¿…éœ€çš„å·¥å…·
    local required_tools=("go" "jq")
    for tool in "${required_tools[@]}"; do
        if ! command -v "$tool" &> /dev/null; then
            log_error "$tool æœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
            exit 1
        fi
    done

    # æ£€æŸ¥å¯é€‰å·¥å…·
    local optional_tools=("pandoc" "wkhtmltopdf" "aws")
    for tool in "${optional_tools[@]}"; do
        if ! command -v "$tool" &> /dev/null; then
            log_warning "$tool æœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨"
        fi
    done

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if [ -n "$INPUT_DIR" ] && [ ! -d "$INPUT_DIR" ]; then
        log_error "è¾“å…¥ç›®å½•ä¸å­˜åœ¨: $INPUT_DIR"
        exit 1
    fi

    # æ£€æŸ¥åŸºå‡†æ–‡ä»¶
    if [ -n "$BASELINE_FILE" ] && [ ! -f "$BASELINE_FILE" ]; then
        log_error "åŸºå‡†æ–‡ä»¶ä¸å­˜åœ¨: $BASELINE_FILE"
        exit 1
    fi

    log_success "ç¯å¢ƒéªŒè¯é€šè¿‡"
}

# å‡†å¤‡æŠ¥å‘Šç¯å¢ƒ
prepare_report_environment() {
    log_info "å‡†å¤‡æŠ¥å‘Šç”Ÿæˆç¯å¢ƒ..."

    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$OUTPUT_DIR"
    mkdir -p "$OUTPUT_DIR/assets"
    mkdir -p "$OUTPUT_DIR/data"
    mkdir -p "$OUTPUT_DIR/archives"

    # è®¾ç½®æ—¶é—´æˆ³
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    REPORT_ID="alex_report_$TIMESTAMP"

    # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
    WORK_DIR=$(mktemp -d)
    export WORK_DIR

    log_success "æŠ¥å‘Šç¯å¢ƒå‡†å¤‡å®Œæˆ"
}

# æ”¶é›†æµ‹è¯•ç»“æœæ•°æ®
collect_test_data() {
    log_info "æ”¶é›†æµ‹è¯•ç»“æœæ•°æ®..."

    local data_dir="$WORK_DIR/data"
    mkdir -p "$data_dir"

    # ç¡®å®šè¾“å…¥æº
    local source_dir="$INPUT_DIR"
    if [ -z "$source_dir" ]; then
        source_dir="$TESTS_ROOT/reports"
    fi

    if [ ! -d "$source_dir" ]; then
        log_warning "æœªæ‰¾åˆ°æµ‹è¯•ç»“æœç›®å½•: $source_dir"
        log_info "åˆ›å»ºç¤ºä¾‹æ•°æ®..."
        create_sample_data "$data_dir"
        return 0
    fi

    # æ”¶é›†ä¸åŒç±»å‹çš„æµ‹è¯•æ•°æ®
    collect_unit_test_results "$source_dir" "$data_dir"
    collect_integration_test_results "$source_dir" "$data_dir"

    if [ "$INCLUDE_PERFORMANCE" = "true" ]; then
        collect_performance_test_results "$source_dir" "$data_dir"
    fi

    if [ "$INCLUDE_COVERAGE" = "true" ]; then
        collect_coverage_data "$source_dir" "$data_dir"
    fi

    if [ "$INCLUDE_ACCEPTANCE" = "true" ]; then
        collect_acceptance_test_results "$source_dir" "$data_dir"
    fi

    log_success "æµ‹è¯•æ•°æ®æ”¶é›†å®Œæˆ"
}

# æ”¶é›†å•å…ƒæµ‹è¯•ç»“æœ
collect_unit_test_results() {
    local source_dir="$1"
    local data_dir="$2"

    log_info "æ”¶é›†å•å…ƒæµ‹è¯•ç»“æœ..."

    # æŸ¥æ‰¾Goæµ‹è¯•è¾“å‡ºæ–‡ä»¶
    find "$source_dir" -name "*.log" -type f | while read -r log_file; do
        if grep -q "=== RUN" "$log_file"; then
            parse_go_test_output "$log_file" "$data_dir/unit_tests.json"
        fi
    done

    # æŸ¥æ‰¾JSONæ ¼å¼çš„æµ‹è¯•ç»“æœ
    find "$source_dir" -name "*test*.json" -type f | while read -r json_file; do
        if jq -e '.Action' "$json_file" >/dev/null 2>&1; then
            process_go_test_json "$json_file" "$data_dir/unit_tests_raw.json"
        fi
    done
}

# æ”¶é›†é›†æˆæµ‹è¯•ç»“æœ
collect_integration_test_results() {
    local source_dir="$1"
    local data_dir="$2"

    log_info "æ”¶é›†é›†æˆæµ‹è¯•ç»“æœ..."

    # æŸ¥æ‰¾é›†æˆæµ‹è¯•æ—¥å¿—
    find "$source_dir" -path "*/integration/*" -name "*.log" -type f | while read -r log_file; do
        parse_integration_test_output "$log_file" "$data_dir/integration_tests.json"
    done
}

# æ”¶é›†æ€§èƒ½æµ‹è¯•ç»“æœ
collect_performance_test_results() {
    local source_dir="$1"
    local data_dir="$2"

    log_info "æ”¶é›†æ€§èƒ½æµ‹è¯•ç»“æœ..."

    # æŸ¥æ‰¾æ€§èƒ½æµ‹è¯•ç»“æœ
    find "$source_dir" -path "*/performance/*" -name "*.json" -type f | while read -r json_file; do
        cp "$json_file" "$data_dir/"
    done

    # å¤„ç†åŸºå‡†æµ‹è¯•ç»“æœ
    find "$source_dir" -name "*bench*.txt" -type f | while read -r bench_file; do
        parse_benchmark_results "$bench_file" "$data_dir/benchmarks.json"
    done
}

# æ”¶é›†è¦†ç›–ç‡æ•°æ®
collect_coverage_data() {
    local source_dir="$1"
    local data_dir="$2"

    log_info "æ”¶é›†è¦†ç›–ç‡æ•°æ®..."

    # æŸ¥æ‰¾è¦†ç›–ç‡æ–‡ä»¶
    find "$source_dir" -name "*.coverage" -o -name "coverage.out" -type f | while read -r coverage_file; do
        process_coverage_file "$coverage_file" "$data_dir/coverage.json"
    done

    # ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
    if [ -f "$data_dir/coverage.json" ]; then
        generate_coverage_summary "$data_dir/coverage.json" "$data_dir/coverage_summary.json"
    fi
}

# æ”¶é›†éªŒæ”¶æµ‹è¯•ç»“æœ
collect_acceptance_test_results() {
    local source_dir="$1"
    local data_dir="$2"

    log_info "æ”¶é›†éªŒæ”¶æµ‹è¯•ç»“æœ..."

    # æ ¹æ®éªŒæ”¶æ ‡å‡†æ£€æŸ¥æµ‹è¯•ç»“æœ
    if [ -f "$TESTS_ROOT/config/acceptance-criteria.yml" ]; then
        evaluate_acceptance_criteria "$TESTS_ROOT/config/acceptance-criteria.yml" "$data_dir" "$data_dir/acceptance.json"
    fi
}

# è§£æGoæµ‹è¯•è¾“å‡º
parse_go_test_output() {
    local log_file="$1"
    local output_file="$2"

    log_info "è§£æGoæµ‹è¯•è¾“å‡º: $(basename "$log_file")"

    # åˆ›å»ºJSONç»“æ„
    cat > "$output_file" << EOF
{
  "source": "$(basename "$log_file")",
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "suites": []
}
EOF

    # è§£ææµ‹è¯•ç»“æœï¼ˆç®€åŒ–å®ç°ï¼‰
    local total_tests=$(grep -c "^=== RUN" "$log_file" 2>/dev/null || echo 0)
    local passed_tests=$(grep -c "^--- PASS:" "$log_file" 2>/dev/null || echo 0)
    local failed_tests=$(grep -c "^--- FAIL:" "$log_file" 2>/dev/null || echo 0)

    # æ›´æ–°JSONæ–‡ä»¶
    jq --arg total "$total_tests" --arg passed "$passed_tests" --arg failed "$failed_tests" \
       '.summary = {total: ($total | tonumber), passed: ($passed | tonumber), failed: ($failed | tonumber)}' \
       "$output_file" > "$output_file.tmp" && mv "$output_file.tmp" "$output_file"
}

# å¤„ç†Goæµ‹è¯•JSONè¾“å‡º
process_go_test_json() {
    local json_file="$1"
    local output_file="$2"

    log_info "å¤„ç†Goæµ‹è¯•JSON: $(basename "$json_file")"

    # ä½¿ç”¨jqå¤„ç†JSONæµ‹è¯•è¾“å‡º
    jq -s 'group_by(.Package) | map({
        package: .[0].Package,
        tests: map(select(.Test != null)) | group_by(.Test) | map({
            name: .[0].Test,
            status: (if any(.Action == "pass") then "passed"
                    elif any(.Action == "fail") then "failed"
                    else "unknown" end),
            duration: (map(select(.Elapsed != null)) | if length > 0 then .[0].Elapsed else null end)
        })
    })' "$json_file" > "$output_file"
}

# è§£æé›†æˆæµ‹è¯•è¾“å‡º
parse_integration_test_output() {
    local log_file="$1"
    local output_file="$2"

    log_info "è§£æé›†æˆæµ‹è¯•è¾“å‡º: $(basename "$log_file")"

    # ç®€åŒ–çš„é›†æˆæµ‹è¯•è§£æ
    local suite_name=$(basename "$log_file" .log)

    cat > "$output_file" << EOF
{
  "suite": "$suite_name",
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "results": {
    "total": $(grep -c "^=== RUN" "$log_file" 2>/dev/null || echo 0),
    "passed": $(grep -c "^--- PASS:" "$log_file" 2>/dev/null || echo 0),
    "failed": $(grep -c "^--- FAIL:" "$log_file" 2>/dev/null || echo 0)
  }
}
EOF
}

# è§£æåŸºå‡†æµ‹è¯•ç»“æœ
parse_benchmark_results() {
    local bench_file="$1"
    local output_file="$2"

    log_info "è§£æåŸºå‡†æµ‹è¯•ç»“æœ: $(basename "$bench_file")"

    # è§£æåŸºå‡†æµ‹è¯•è¾“å‡ºæ ¼å¼
    # BenchmarkTest-8    1000000    1234 ns/op    456 B/op    7 allocs/op
    awk '/^Benchmark/ {
        name = $1
        gsub(/-[0-9]+$/, "", name)
        print "{"
        print "  \"name\": \"" name "\","
        print "  \"iterations\": " $2 ","
        print "  \"ns_per_op\": " $3 ","
        if (NF >= 5) print "  \"bytes_per_op\": " $4 ","
        if (NF >= 7) print "  \"allocs_per_op\": " $6
        print "},"
    }' "$bench_file" | sed '$ s/,$//' | {
        echo '{"benchmarks": ['
        cat
        echo ']}'
    } > "$output_file"
}

# å¤„ç†è¦†ç›–ç‡æ–‡ä»¶
process_coverage_file() {
    local coverage_file="$1"
    local output_file="$2"

    log_info "å¤„ç†è¦†ç›–ç‡æ–‡ä»¶: $(basename "$coverage_file")"

    # ä½¿ç”¨go tool coverå¤„ç†è¦†ç›–ç‡
    if command -v go &> /dev/null; then
        # ç”Ÿæˆå‡½æ•°çº§è¦†ç›–ç‡
        go tool cover -func="$coverage_file" > "$WORK_DIR/coverage_func.txt" 2>/dev/null || true

        # è§£æè¦†ç›–ç‡æ•°æ®
        if [ -f "$WORK_DIR/coverage_func.txt" ]; then
            awk '/^total:/ {print "{\"overall_coverage\": " $3 "}"}' "$WORK_DIR/coverage_func.txt" > "$output_file"
        fi
    fi
}

# ç”Ÿæˆè¦†ç›–ç‡æ‘˜è¦
generate_coverage_summary() {
    local coverage_json="$1"
    local output_file="$2"

    log_info "ç”Ÿæˆè¦†ç›–ç‡æ‘˜è¦..."

    # ç®€åŒ–çš„è¦†ç›–ç‡æ‘˜è¦
    jq '. + {
        "goal_met": (.overall_coverage > 80),
        "rating": (if .overall_coverage > 90 then "excellent"
                  elif .overall_coverage > 80 then "good"
                  elif .overall_coverage > 70 then "fair"
                  else "poor" end)
    }' "$coverage_json" > "$output_file"
}

# è¯„ä¼°éªŒæ”¶æ ‡å‡†
evaluate_acceptance_criteria() {
    local criteria_file="$1"
    local data_dir="$2"
    local output_file="$3"

    log_info "è¯„ä¼°éªŒæ”¶æ ‡å‡†..."

    # è¯»å–éªŒæ”¶æ ‡å‡†å¹¶è¯„ä¼°
    # è¿™é‡Œéœ€è¦å®ç°YAMLè§£æå’Œæ ‡å‡†è¯„ä¼°é€»è¾‘
    # ç®€åŒ–å®ç°
    cat > "$output_file" << EOF
{
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "overall_status": "in_progress",
  "categories": [
    {
      "name": "functional_requirements",
      "status": "passed",
      "score": 85.5
    },
    {
      "name": "performance_requirements",
      "status": "partial",
      "score": 75.2
    },
    {
      "name": "security_requirements",
      "status": "passed",
      "score": 92.1
    }
  ]
}
EOF
}

# åˆ›å»ºç¤ºä¾‹æ•°æ®
create_sample_data() {
    local data_dir="$1"

    log_info "åˆ›å»ºç¤ºä¾‹æµ‹è¯•æ•°æ®..."

    # åˆ›å»ºç¤ºä¾‹å•å…ƒæµ‹è¯•ç»“æœ
    cat > "$data_dir/unit_tests.json" << EOF
{
  "source": "sample",
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "summary": {
    "total": 150,
    "passed": 145,
    "failed": 3,
    "skipped": 2
  }
}
EOF

    # åˆ›å»ºç¤ºä¾‹æ€§èƒ½æµ‹è¯•ç»“æœ
    cat > "$data_dir/performance.json" << EOF
{
  "load_tests": [
    {
      "name": "api_load_test",
      "concurrency": 50,
      "requests_per_second": 125.5,
      "success_rate": 99.2,
      "average_latency": "45ms"
    }
  ]
}
EOF

    # åˆ›å»ºç¤ºä¾‹è¦†ç›–ç‡æ•°æ®
    cat > "$data_dir/coverage.json" << EOF
{
  "overall_coverage": 87.5,
  "goal_met": true,
  "rating": "good"
}
EOF
}

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
generate_comprehensive_report() {
    log_info "ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š..."

    local data_dir="$WORK_DIR/data"
    local report_data="$WORK_DIR/report_data.json"

    # åˆå¹¶æ‰€æœ‰æ•°æ®æº
    merge_test_data "$data_dir" "$report_data"

    # æ ¹æ®æ ¼å¼ç”ŸæˆæŠ¥å‘Š
    case "$FORMAT" in
        "html")
            generate_html_report "$report_data"
            ;;
        "json")
            generate_json_report "$report_data"
            ;;
        "markdown")
            generate_markdown_report "$report_data"
            ;;
        "csv")
            generate_csv_report "$report_data"
            ;;
        "all")
            generate_html_report "$report_data"
            generate_json_report "$report_data"
            generate_markdown_report "$report_data"
            generate_csv_report "$report_data"
            ;;
        *)
            log_error "ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: $FORMAT"
            exit 1
            ;;
    esac

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    if [ -n "$BASELINE_FILE" ]; then
        generate_comparison_report "$report_data" "$BASELINE_FILE"
    fi

    log_success "ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ"
}

# åˆå¹¶æµ‹è¯•æ•°æ®
merge_test_data() {
    local data_dir="$1"
    local output_file="$2"

    log_info "åˆå¹¶æµ‹è¯•æ•°æ®..."

    # åˆ›å»ºåŸºç¡€æŠ¥å‘Šç»“æ„
    cat > "$output_file" << EOF
{
  "metadata": {
    "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "report_id": "$REPORT_ID",
    "version": "1.0.0",
    "generator": "alex-test-report"
  },
  "summary": {},
  "unit_tests": {},
  "integration_tests": {},
  "performance": {},
  "coverage": {},
  "acceptance": {}
}
EOF

    # åˆå¹¶å„ç§æ•°æ®æ–‡ä»¶
    for data_file in "$data_dir"/*.json; do
        if [ -f "$data_file" ]; then
            local filename=$(basename "$data_file" .json)
            jq --slurpfile data "$data_file" ".$filename = \$data[0]" "$output_file" > "$output_file.tmp" && mv "$output_file.tmp" "$output_file"
        fi
    done

    # è®¡ç®—æ€»ä½“æ‘˜è¦
    calculate_overall_summary "$output_file"
}

# è®¡ç®—æ€»ä½“æ‘˜è¦
calculate_overall_summary() {
    local report_file="$1"

    log_info "è®¡ç®—æ€»ä½“æ‘˜è¦..."

    # ä½¿ç”¨jqè®¡ç®—æ‘˜è¦ç»Ÿè®¡
    jq '.summary = {
        total_tests: ((.unit_tests.summary.total // 0) + (.integration_tests.results.total // 0)),
        passed_tests: ((.unit_tests.summary.passed // 0) + (.integration_tests.results.passed // 0)),
        failed_tests: ((.unit_tests.summary.failed // 0) + (.integration_tests.results.failed // 0)),
        pass_rate: ((((.unit_tests.summary.passed // 0) + (.integration_tests.results.passed // 0)) /
                    ((.unit_tests.summary.total // 0) + (.integration_tests.results.total // 0))) * 100),
        overall_status: (if (.summary.pass_rate // 0) > 95 then "excellent"
                        elif (.summary.pass_rate // 0) > 85 then "good"
                        elif (.summary.pass_rate // 0) > 70 then "fair"
                        else "poor" end)
    }' "$report_file" > "$report_file.tmp" && mv "$report_file.tmp" "$report_file"
}

# ç”ŸæˆHTMLæŠ¥å‘Š
generate_html_report() {
    local report_data="$1"

    log_info "ç”ŸæˆHTMLæŠ¥å‘Š..."

    local html_file="$OUTPUT_DIR/test_report_$TIMESTAMP.html"

    # ä½¿ç”¨Goç¨‹åºç”ŸæˆHTMLæŠ¥å‘Š
    if [ -f "$TESTS_ROOT/utils/report-generator.go" ]; then
        cd "$TESTS_ROOT"
        go run utils/report-generator.go -input "$report_data" -output "$html_file" -format html
    else
        # å¤‡ç”¨ï¼šç®€å•çš„HTMLç”Ÿæˆ
        generate_simple_html_report "$report_data" "$html_file"
    fi

    log_success "HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: $html_file"
}

# ç”Ÿæˆç®€å•HTMLæŠ¥å‘Š
generate_simple_html_report() {
    local report_data="$1"
    local html_file="$2"

    # è¯»å–æ•°æ®
    local total_tests=$(jq -r '.summary.total_tests // 0' "$report_data")
    local pass_rate=$(jq -r '.summary.pass_rate // 0' "$report_data")
    local overall_status=$(jq -r '.summary.overall_status // "unknown"' "$report_data")

    cat > "$html_file" << EOF
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ALEX æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
        .container { max-width: 1000px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .header { text-align: center; border-bottom: 2px solid #007acc; padding-bottom: 20px; margin-bottom: 30px; }
        .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }
        .card h3 { margin: 0 0 10px 0; }
        .card .value { font-size: 2em; font-weight: bold; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ALEX æµ‹è¯•æŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: $(date)</p>
        </div>
        <div class="summary">
            <div class="card">
                <h3>æ€»æµ‹è¯•æ•°</h3>
                <div class="value">$total_tests</div>
            </div>
            <div class="card">
                <h3>é€šè¿‡ç‡</h3>
                <div class="value">$(printf "%.1f%%" "$pass_rate")</div>
            </div>
            <div class="card">
                <h3>æ€»ä½“çŠ¶æ€</h3>
                <div class="value">$overall_status</div>
            </div>
        </div>
        <div>
            <h2>è¯¦ç»†æ•°æ®</h2>
            <pre>$(jq '.' "$report_data")</pre>
        </div>
    </div>
</body>
</html>
EOF
}

# ç”ŸæˆJSONæŠ¥å‘Š
generate_json_report() {
    local report_data="$1"

    log_info "ç”ŸæˆJSONæŠ¥å‘Š..."

    local json_file="$OUTPUT_DIR/test_report_$TIMESTAMP.json"
    cp "$report_data" "$json_file"

    log_success "JSONæŠ¥å‘Šå·²ç”Ÿæˆ: $json_file"
}

# ç”ŸæˆMarkdownæŠ¥å‘Š
generate_markdown_report() {
    local report_data="$1"

    log_info "ç”ŸæˆMarkdownæŠ¥å‘Š..."

    local md_file="$OUTPUT_DIR/test_report_$TIMESTAMP.md"

    # è¯»å–æ•°æ®
    local total_tests=$(jq -r '.summary.total_tests // 0' "$report_data")
    local passed_tests=$(jq -r '.summary.passed_tests // 0' "$report_data")
    local failed_tests=$(jq -r '.summary.failed_tests // 0' "$report_data")
    local pass_rate=$(jq -r '.summary.pass_rate // 0' "$report_data")
    local overall_status=$(jq -r '.summary.overall_status // "unknown"' "$report_data")

    cat > "$md_file" << EOF
# ALEX æµ‹è¯•æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´:** $(date)
**æŠ¥å‘ŠID:** $REPORT_ID

## ğŸ“Š æµ‹è¯•æ‘˜è¦

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| æ€»æµ‹è¯•æ•° | $total_tests |
| é€šè¿‡æµ‹è¯• | $passed_tests |
| å¤±è´¥æµ‹è¯• | $failed_tests |
| é€šè¿‡ç‡ | $(printf "%.2f%%" "$pass_rate") |
| æ€»ä½“çŠ¶æ€ | $overall_status |

## ğŸ“‹ è¯¦ç»†ç»“æœ

EOF

    # æ·»åŠ è¯¦ç»†æ•°æ®
    echo '```json' >> "$md_file"
    jq '.' "$report_data" >> "$md_file"
    echo '```' >> "$md_file"

    log_success "MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: $md_file"
}

# ç”ŸæˆCSVæŠ¥å‘Š
generate_csv_report() {
    local report_data="$1"

    log_info "ç”ŸæˆCSVæŠ¥å‘Š..."

    local csv_file="$OUTPUT_DIR/test_data_$TIMESTAMP.csv"

    # åˆ›å»ºCSVæ–‡ä»¶
    cat > "$csv_file" << EOF
Category,Metric,Value,Unit
Summary,TotalTests,$(jq -r '.summary.total_tests // 0' "$report_data"),count
Summary,PassedTests,$(jq -r '.summary.passed_tests // 0' "$report_data"),count
Summary,FailedTests,$(jq -r '.summary.failed_tests // 0' "$report_data"),count
Summary,PassRate,$(jq -r '.summary.pass_rate // 0' "$report_data"),percent
Coverage,OverallCoverage,$(jq -r '.coverage.overall_coverage // 0' "$report_data"),percent
EOF

    log_success "CSVæŠ¥å‘Šå·²ç”Ÿæˆ: $csv_file"
}

# ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
generate_comparison_report() {
    local current_data="$1"
    local baseline_file="$2"

    log_info "ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š..."

    local comparison_file="$OUTPUT_DIR/comparison_report_$TIMESTAMP.json"

    # åˆ›å»ºå¯¹æ¯”æ•°æ®
    jq -s '.[0] as $current | .[1] as $baseline | {
        current: $current,
        baseline: $baseline,
        comparison: {
            pass_rate_change: (($current.summary.pass_rate // 0) - ($baseline.summary.pass_rate // 0)),
            test_count_change: (($current.summary.total_tests // 0) - ($baseline.summary.total_tests // 0)),
            coverage_change: (($current.coverage.overall_coverage // 0) - ($baseline.coverage.overall_coverage // 0))
        }
    }' "$current_data" "$baseline_file" > "$comparison_file"

    log_success "å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: $comparison_file"
}

# å‘é€æŠ¥å‘Š
send_report() {
    log_info "å‘é€æŠ¥å‘Š..."

    # å‘é€é‚®ä»¶
    if [ -n "$EMAIL_RECIPIENT" ]; then
        send_email_report
    fi

    # ä¸Šä¼ åˆ°S3
    if [ -n "$S3_BUCKET" ]; then
        upload_to_s3
    fi

    # å‘é€åˆ°webhook
    if [ -n "$WEBHOOK_URL" ]; then
        send_webhook_notification
    fi
}

# å‘é€é‚®ä»¶æŠ¥å‘Š
send_email_report() {
    log_info "å‘é€é‚®ä»¶æŠ¥å‘Šåˆ°: $EMAIL_RECIPIENT"

    # æŸ¥æ‰¾é‚®ä»¶é…ç½®
    local email_config="${EMAIL_CONFIG:-$HOME/.alex/email-config}"

    if [ ! -f "$email_config" ]; then
        log_warning "é‚®ä»¶é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡é‚®ä»¶å‘é€"
        return 0
    fi

    # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„é‚®ä»¶å‘é€é€»è¾‘
    log_info "é‚®ä»¶å‘é€åŠŸèƒ½éœ€è¦é…ç½®SMTPæœåŠ¡å™¨"
}

# ä¸Šä¼ åˆ°S3
upload_to_s3() {
    log_info "ä¸Šä¼ æŠ¥å‘Šåˆ°S3: $S3_BUCKET"

    if ! command -v aws &> /dev/null; then
        log_warning "AWS CLIæœªå®‰è£…ï¼Œè·³è¿‡S3ä¸Šä¼ "
        return 0
    fi

    # ä¸Šä¼ æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
    aws s3 sync "$OUTPUT_DIR" "s3://$S3_BUCKET/test-reports/$TIMESTAMP/" --exclude "*" --include "test_report_*"

    log_success "æŠ¥å‘Šå·²ä¸Šä¼ åˆ°S3"
}

# å‘é€Webhooké€šçŸ¥
send_webhook_notification() {
    log_info "å‘é€Webhooké€šçŸ¥åˆ°: $WEBHOOK_URL"

    # åˆ›å»ºé€šçŸ¥è´Ÿè½½
    local payload=$(jq -n \
        --arg timestamp "$TIMESTAMP" \
        --arg status "$(jq -r '.summary.overall_status // "unknown"' "$WORK_DIR/report_data.json")" \
        --arg pass_rate "$(jq -r '.summary.pass_rate // 0' "$WORK_DIR/report_data.json")" \
        '{
            report_id: $timestamp,
            status: $status,
            pass_rate: ($pass_rate | tonumber),
            timestamp: now,
            url: "'"$OUTPUT_DIR"'"
        }')

    # å‘é€HTTP POSTè¯·æ±‚
    if command -v curl &> /dev/null; then
        curl -X POST "$WEBHOOK_URL" \
             -H "Content-Type: application/json" \
             -d "$payload" || log_warning "Webhookå‘é€å¤±è´¥"
    else
        log_warning "curlæœªå®‰è£…ï¼Œæ— æ³•å‘é€Webhook"
    fi
}

# æ¸…ç†å·¥ä½œç›®å½•
cleanup() {
    if [ -n "$WORK_DIR" ] && [ -d "$WORK_DIR" ]; then
        log_info "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
        rm -rf "$WORK_DIR"
    fi
}

# ä¸»å‡½æ•°
main() {
    # è®¾ç½®æ¸…ç†é™·é˜±
    trap cleanup EXIT

    log_header "ALEX æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ"

    # è§£æå‚æ•°
    parse_args "$@"

    # æ˜¾ç¤ºé…ç½®
    log_info "è¾“å‡ºç›®å½•: $OUTPUT_DIR"
    log_info "æŠ¥å‘Šæ ¼å¼: $FORMAT"
    log_info "æŠ¥å‘Šæ¨¡æ¿: $TEMPLATE"
    if [ -n "$INPUT_DIR" ]; then
        log_info "è¾“å…¥ç›®å½•: $INPUT_DIR"
    fi

    # éªŒè¯ç¯å¢ƒ
    validate_environment

    # å‡†å¤‡ç¯å¢ƒ
    prepare_report_environment

    # æ”¶é›†æ•°æ®
    collect_test_data

    # ç”ŸæˆæŠ¥å‘Š
    generate_comprehensive_report

    # å‘é€æŠ¥å‘Š
    send_report

    # æœ€ç»ˆæ¶ˆæ¯
    log_header "æŠ¥å‘Šç”Ÿæˆå®Œæˆ"
    log_success "æŠ¥å‘Šæ–‡ä»¶å·²ä¿å­˜åˆ°: $OUTPUT_DIR"
    log_info "æŠ¥å‘ŠID: $REPORT_ID"

    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    log_info "ç”Ÿæˆçš„æ–‡ä»¶:"
    find "$OUTPUT_DIR" -name "*$TIMESTAMP*" -type f | while read -r file; do
        log_info "  - $(basename "$file")"
    done
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
