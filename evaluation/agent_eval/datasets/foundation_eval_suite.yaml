version: "1"
name: "foundation-offline-layered-suite"
description: "Hard-only offline foundation evaluation with layered difficulty: Core-Hard (SWE/coordination/conflict/delivery stress), Frontier-Hard (Terminal-Bench/MLE-Bench/SWE-PolyBench/GitTaskBench/OSWorld-G), and Research-Frontier-Hard (FrontierMath/HLE/RE-Bench/EXP-Bench/ARC-AGI-2/PaperBench/MLRC-Bench/ALE-Bench). Saturated easy/basic collections are retired from the main suite."
collections:
  - id: "architecture-coding-hard"
    name: "Architecture Coding Hard"
    dimension: "architecture_coding_hard"
    description: "Routing quality for complex architecture refactors and logic-heavy coding tasks"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_architecture_coding_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 3

  - id: "conflict-convergence-hard"
    name: "Conflict Convergence Hard"
    dimension: "conflict_convergence_hard"
    description: "Hard conflict-focused convergence set for overlapping tools and sandbox-intent normalization"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_conflict_convergence_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 3

  - id: "industry-benchmark-swebench-verified-hard-plus"
    name: "Industry Benchmark SWE-bench Verified Hard Plus"
    dimension: "industry_benchmark_swebench_verified_hard_plus"
    description: "Hard-plus transfer set mapped from difficult SWE-bench Verified multi-file and regression-guarded patch workflows"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_swebench_verified_hard_plus.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-cybench-security-ops-hard"
    name: "Industry Benchmark CyBench Security Ops Hard"
    dimension: "industry_benchmark_cybench_security_ops_hard"
    description: "Hard transfer set mapped from CyBench-style security operations, triage, remediation, and evidence packaging flows"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_cybench_security_ops_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-tau2-long-horizon-enterprise-hard"
    name: "Industry Benchmark tau2 Long-Horizon Enterprise Hard"
    dimension: "industry_benchmark_tau2_long_horizon_enterprise_hard"
    description: "Hard transfer set mapped from tau2/AssistantBench long-horizon enterprise state, approval, and handoff constraints"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_tau2_long_horizon_enterprise_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "complex-artifact-delivery"
    name: "Complex Artifact Delivery"
    dimension: "complex_artifact_delivery"
    description: "Complex tasks that require concrete artifact/file outputs, traceability checks, and publish workflows"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_complex_artifact_delivery.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "sparse-clue-retrieval-stress"
    name: "Sparse-Clue Retrieval Stress"
    dimension: "sparse_clue_retrieval_stress"
    description: "BrowseComp-like sparse clue retrieval and source/memory/repo disambiguation stress"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_sparse_clue_retrieval.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "stateful-commitment-boundary-stress"
    name: "Stateful Commitment Boundary Stress"
    dimension: "stateful_commitment_boundary_stress"
    description: "TAU-bench-like stateful multi-turn commitment and mutation-boundary disambiguation stress"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_stateful_commitment_boundary.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "reproducibility-trace-evidence-stress"
    name: "Reproducibility Trace Evidence Stress"
    dimension: "reproducibility_trace_evidence_stress"
    description: "WebArena-Verified/SWE-Verified style reproducibility, traceability, and publish-gate routing stress"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_reproducibility_trace_evidence.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-web-and-computer-use"
    name: "Industry Benchmark Web and Computer Use"
    dimension: "industry_benchmark_web_and_computer_use"
    description: "Transfer set mapped from WebArena, BrowseComp, OSWorld, and WebChoreArena"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_web_and_computer_use.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-long-context-reasoning"
    name: "Industry Benchmark Long-Context Reasoning"
    dimension: "industry_benchmark_long_context_reasoning"
    description: "Transfer set mapped from LongBench v2, RULER, and InfiniteBench-style long-context reasoning stress"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_long_context_reasoning.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-general-assistant-gaia"
    name: "Industry Benchmark General Assistant GAIA"
    dimension: "industry_benchmark_general_assistant_gaia"
    description: "Transfer set mapped from GAIA-style general assistant tasks with gated actions and tool-use disambiguation"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_general_assistant_gaia.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-real-world-coding-livecodebench-swelancer"
    name: "Industry Benchmark Real-World Coding LiveCodeBench SWE-Lancer"
    dimension: "industry_benchmark_real_world_coding_livecodebench_swelancer"
    description: "Transfer set mapped from LiveCodeBench and SWE-Lancer real-world coding failure modes"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_real_world_coding_livecodebench_swelancer.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-context-learning-nolima-longmemeval-babilong"
    name: "Industry Benchmark Context Learning NoLiMa LongMemEval BABILong"
    dimension: "industry_benchmark_context_learning_nolima_longmemeval_babilong"
    description: "Transfer set mapped from NoLiMa, LongMemEval, and BABILong context-learning failure modes"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_context_learning_nolima_longmemeval_babilong.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-implicit-intent-boundary-low-overlap"
    name: "Industry Benchmark Implicit Intent Boundary Low Overlap"
    dimension: "industry_benchmark_implicit_intent_boundary_low_overlap"
    description: "Low-lexical-overlap implicit intent routing transfer set focused on boundary disambiguation"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_implicit_intent_boundary_low_overlap.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-autonomy-long-horizon-value-delivery"
    name: "Industry Benchmark Autonomy Long Horizon Value Delivery"
    dimension: "industry_benchmark_autonomy_long_horizon_value_delivery"
    description: "Compound long-horizon autonomy tasks with implicit constraints, evidence contracts, and high-value deliverables"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_autonomy_long_horizon_value_delivery.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-terminal-bench-ops-hard"
    name: "Industry Benchmark Terminal-Bench Ops Hard"
    dimension: "industry_benchmark_terminal_bench_ops_hard"
    description: "Transfer set mapped from Terminal-Bench style terminal-first diagnosis, bounded mutation, and release gating"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_terminal_bench_ops_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-mle-bench-experiment-lifecycle-hard"
    name: "Industry Benchmark MLE-Bench Experiment Lifecycle Hard"
    dimension: "industry_benchmark_mle_bench_experiment_lifecycle_hard"
    description: "Transfer set mapped from MLE-Bench style experiment lifecycle, reproducibility, and artifactized reporting"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_mle_bench_experiment_lifecycle_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-swe-polybench-cross-language-repo-hard"
    name: "Industry Benchmark SWE-PolyBench Cross-Language Repo Hard"
    dimension: "industry_benchmark_swe_polybench_cross_language_repo_hard"
    description: "Transfer set mapped from SWE-PolyBench style cross-language and cross-repo engineering workflows"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_swe_polybench_cross_language_repo_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-gittaskbench-real-repo-maintenance-hard"
    name: "Industry Benchmark GitTaskBench Real Repo Maintenance Hard"
    dimension: "industry_benchmark_gittaskbench_real_repo_maintenance_hard"
    description: "Transfer set mapped from GitTaskBench style real-repo maintenance and policy-bound execution"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_gittaskbench_real_repo_maintenance_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-osworld-g-grounded-computer-use-hard"
    name: "Industry Benchmark OSWorld-G Grounded Computer Use Hard"
    dimension: "industry_benchmark_osworld_g_grounded_computer_use_hard"
    description: "Transfer set mapped from OSWorld-G style grounded multimodal computer-use and modality-boundary routing"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_osworld_g_grounded_computer_use_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-frontiermath-hle-deep-reasoning-validation-hard"
    name: "Industry Benchmark FrontierMath HLE Deep Reasoning Validation Hard"
    dimension: "industry_benchmark_frontiermath_hle_deep_reasoning_validation_hard"
    description: "Transfer set mapped from FrontierMath and HLE style deep reasoning with deterministic validation and evidence gates"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_frontiermath_hle_deep_reasoning_validation_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-re-bench-frontier-ml-rd-hard"
    name: "Industry Benchmark RE-Bench Frontier ML R&D Hard"
    dimension: "industry_benchmark_re_bench_frontier_ml_rd_hard"
    description: "Transfer set mapped from METR RE-Bench frontier ML R&D engineering tasks"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_re_bench_frontier_ml_rd_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-exp-bench-autonomous-research-hard"
    name: "Industry Benchmark EXP-Bench Autonomous Research Hard"
    dimension: "industry_benchmark_exp_bench_autonomous_research_hard"
    description: "Transfer set mapped from EXP-Bench autonomous AI research experimentation tasks"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_exp_bench_autonomous_research_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-arc-agi2-abductive-reasoning-hard"
    name: "Industry Benchmark ARC-AGI-2 Abductive Reasoning Hard"
    dimension: "industry_benchmark_arc_agi2_abductive_reasoning_hard"
    description: "Transfer set mapped from ARC-AGI-2 style abductive reasoning and strict verification gating"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_arc_agi2_abductive_reasoning_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-paperbench-full-reproduction-hard"
    name: "Industry Benchmark PaperBench Full Reproduction Hard"
    dimension: "industry_benchmark_paperbench_full_reproduction_hard"
    description: "Transfer set mapped from PaperBench style end-to-end ML paper reproduction"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_paperbench_full_reproduction_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-mlrc-bench-open-research-hard"
    name: "Industry Benchmark MLRC-Bench Open Research Hard"
    dimension: "industry_benchmark_mlrc_bench_open_research_hard"
    description: "Transfer set mapped from MLRC-Bench style open-ended ML research competition tasks"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_mlrc_bench_open_research_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5

  - id: "industry-benchmark-ale-bench-long-horizon-algo-engineering-hard"
    name: "Industry Benchmark ALE-Bench Long Horizon Algo Engineering Hard"
    dimension: "industry_benchmark_ale_bench_long_horizon_algo_engineering_hard"
    description: "Transfer set mapped from ALE-Bench long-horizon algorithm engineering tasks"
    cases_path: "evaluation/agent_eval/datasets/foundation_eval_cases_industry_benchmark_ale_bench_long_horizon_algo_engineering_hard.yaml"
    mode: "web"
    preset: "full"
    toolset: "default"
    top_k: 5
