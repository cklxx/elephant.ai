package agent

import (
	"context"
	"fmt"
	"strings"
	"time"

	"alex/internal/llm"
	"alex/internal/session"
	"alex/internal/utils"
	"alex/pkg/types"
)

// ========== Sub-Agent Logging ==========

// Using the new unified logging system
var subAgentLogger = utils.SubAgentLogger

// subAgentLog - ä¸ºå‘åå…¼å®¹ä¿ç•™çš„åŒ…è£…å‡½æ•°
func subAgentLog(level, format string, args ...interface{}) {
	switch level {
	case "DEBUG":
		subAgentLogger.Debug(format, args...)
	case "INFO":
		subAgentLogger.Info(format, args...)
	case "WARN":
		subAgentLogger.Warn(format, args...)
	case "ERROR":
		subAgentLogger.Error(format, args...)
	default:
		subAgentLogger.Info(format, args...)
	}
}

// ========== Core Task Execution Abstraction ==========

// TaskExecutionContext - ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œæ”¯æŒsessionéš”ç¦»
type TaskExecutionContext struct {
	TaskID         string
	Task           string
	Messages       []llm.Message
	TaskCtx        *types.ReactTaskContext
	Tools          []llm.Tool
	Config         *llm.Config
	MaxIter        int
	Session        *session.Session // æ”¯æŒç‹¬ç«‹çš„sessionä¸Šä¸‹æ–‡
	SessionManager *session.Manager // æ”¯æŒç‹¬ç«‹çš„session manager
}

// TaskExecutionResult - ä»»åŠ¡æ‰§è¡Œç»“æœ
type TaskExecutionResult struct {
	Answer               string
	Success              bool
	Confidence           float64
	TokensUsed           int
	PromptTokens         int
	CompletionTokens     int
	CurrentMessageTokens int // å½“å‰æ¶ˆæ¯tokenæ•°ï¼Œå‹ç¼©åä¼šæ¸…é›¶
	History              []types.ReactExecutionStep
	Messages             []llm.Message // è¿”å›æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
}

// ExecuteTaskCore - æ ¸å¿ƒä»»åŠ¡æ‰§è¡Œé€»è¾‘ï¼Œä¸ä¾èµ–sessionå’Œmessageç®¡ç†
// ä¸ºsub-agentæ¶æ„å‡†å¤‡çš„ç‹¬ç«‹æ‰§è¡Œå‡½æ•°
func (rc *ReactCore) ExecuteTaskCore(ctx context.Context, execCtx *TaskExecutionContext, streamCallback StreamCallback) (*TaskExecutionResult, error) {
	if execCtx == nil {
		return nil, fmt.Errorf("execution context cannot be nil")
	}

	// åˆå§‹åŒ–æ‰§è¡Œç»“æœ
	result := &TaskExecutionResult{
		Success:    false,
		Confidence: 0.0,
		Messages:   make([]llm.Message, len(execCtx.Messages)),
	}
	copy(result.Messages, execCtx.Messages)

	// è®¾ç½®é»˜è®¤æœ€å¤§è¿­ä»£æ•°
	maxIterations := execCtx.MaxIter
	if maxIterations <= 0 {
		maxIterations = 100
	}

	// å†³å®šæ˜¯å¦ä½¿ç”¨æµå¼å¤„ç†
	isStreaming := streamCallback != nil
	// æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ˜¾ç¤ºåˆå§‹çŠ¶æ€æ¶ˆæ¯ï¼Œé¿å…ä¸SolveTaskä¸­çš„æ¶ˆæ¯é‡å¤

	// æ‰§è¡Œæ ¸å¿ƒReActå¾ªç¯
	for iteration := 1; iteration <= maxIterations; iteration++ {
		step := types.ReactExecutionStep{
			Number:    iteration,
			Timestamp: time.Now(),
		}

		subAgentLog("INFO", "ğŸ”„ Starting iteration %d/%d", iteration, maxIterations)

		// Optimized message queue handling for subagents:
		// SubAgents should focus on their assigned task without interruption from new user messages
		// Only check for pending messages in main agent context (not subagents)
		// This prevents performance issues and race conditions in parallel execution
		if rc.agent != nil && rc.agent.HasPendingMessages() && !isSubAgentContext(execCtx) {
			subAgentLog("DEBUG", "ğŸ“¬ Main agent detected pending messages, integrating into current task")

			// æ”¶é›†æ‰€æœ‰å¾…å¤„ç†çš„æ¶ˆæ¯ (ä»…åœ¨ä¸» agent ä¸­)
			var newMessages []string
			for rc.agent.HasPendingMessages() && len(newMessages) < 5 { // Limit message integration to prevent overflow
				if pendingItem, hasItem := rc.agent.CheckPendingMessages(); hasItem {
					newMessages = append(newMessages, pendingItem.Message)
					subAgentLog("DEBUG", "ğŸ“¬ Integrating message: %s", pendingItem.Message)
				}
			}

			if len(newMessages) > 0 {
				if isStreaming {
					streamCallback(StreamChunk{
						Type:     "message_integration",
						Content:  fmt.Sprintf("ğŸ“¬ Integrating %d new messages into current task", len(newMessages)),
						Metadata: map[string]any{"iteration": iteration, "phase": "message_integration", "new_messages_count": len(newMessages)},
					})
				}

				// å°†æ–°æ¶ˆæ¯èå…¥åˆ°å½“å‰å¯¹è¯ä¸­ï¼Œæ›´æ–°ä»»åŠ¡ç›®æ ‡
				combinedMessage := "Additional user messages received:\n"
				for i, msg := range newMessages {
					combinedMessage += fmt.Sprintf("%d. %s\n", i+1, msg)
				}
				combinedMessage += "\nPlease integrate these new requirements with the current task and continue working."

				// æ·»åŠ èåˆæ¶ˆæ¯åˆ°LLMå¯¹è¯å†å²
				userMsg := llm.Message{
					Role:    "user",
					Content: combinedMessage,
				}
				result.Messages = append(result.Messages, userMsg)

				subAgentLog("DEBUG", "ğŸ“¬ Successfully integrated %d messages into current task", len(newMessages))
			}
		} else if isSubAgentContext(execCtx) {
			// SubAgent should focus on assigned task without message queue interruption
			subAgentLog("DEBUG", "SubAgent context: skipping message queue check for focused execution")
		}

		if isStreaming {
			streamCallback(StreamChunk{
				Type:     "iteration",
				Content:  fmt.Sprintf("ğŸ”„ Core Iteration %d: Processing...", iteration),
				Metadata: map[string]any{"iteration": iteration, "phase": "core_processing"},
			})
		}

		// SubAgent ä¼˜åŒ–çš„æ¶ˆæ¯å‹ç¼©ç³»ç»Ÿ - ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼å’Œæ›´å¥½çš„é”™è¯¯å¤„ç†
		if rc.messageProcessor != nil {
			// SubAgent ä½¿ç”¨æ›´ä¸¥æ ¼çš„å‹ç¼©ç­–ç•¥ï¼šè¾ƒä½çš„ token é˜ˆå€¼å’Œæ¶ˆæ¯æ•°é‡é˜ˆå€¼
			totalTokensUsed := result.PromptTokens + result.CompletionTokens
			currentTokens := result.CurrentMessageTokens
			messageCount := len(result.Messages)

			// SubAgent ç‰¹å®šçš„å‹ç¼©é˜ˆå€¼ï¼ˆæ¯”ä¸» agent æ›´ä½ï¼‰
			const (
				subAgentTokenThreshold   = 50000 // 50K token é™åˆ¶ï¼ˆä¸» agent æ˜¯ 100Kï¼‰
				subAgentMessageThreshold = 10    // 10 æ¡æ¶ˆæ¯ï¼ˆä¸» agent æ˜¯ 15ï¼‰
				subAgentForceThreshold   = 30000 // 30K token å¼ºåˆ¶å‹ç¼©é˜ˆå€¼
			)

			shouldCompress := false
			compressReason := ""

			// åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
			if iteration > 1 && (messageCount > subAgentMessageThreshold && currentTokens > subAgentTokenThreshold) {
				shouldCompress = true
				compressReason = "normal_threshold"
			} else if currentTokens > subAgentForceThreshold {
				// å¼ºåˆ¶å‹ç¼©ï¼šå½“ token æ•°è¿‡é«˜æ—¶ï¼Œå³ä½¿åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¹Ÿè¦å‹ç¼©
				shouldCompress = true
				compressReason = "force_threshold"
			} else if isSubAgentContext(execCtx) && messageCount > 8 {
				// SubAgent ä¸“ç”¨é€»è¾‘ï¼šå³ä½¿ token ä¸å¤šï¼Œä¹Ÿè¦æ§åˆ¶æ¶ˆæ¯æ•°é‡
				shouldCompress = true
				compressReason = "subagent_message_limit"
			}

			if shouldCompress {
				subAgentLog("INFO", "ğŸ’¾ SubAgent compressing messages at iteration %d (reason: %s): %d messages, %d tokens",
					iteration, compressReason, messageCount, currentTokens)

				// æ‰§è¡Œå‹ç¼©ï¼Œå¸¦æœ‰å®Œå–„çš„é”™è¯¯å¤„ç†
				compressedMessages, newConsumedTokens, newCurrentTokens := rc.compressMessagesWithFallback(ctx, result.Messages, totalTokensUsed, currentTokens, iteration)

				if compressedMessages != nil {
					// å‹ç¼©æˆåŠŸ
					result.CurrentMessageTokens = newCurrentTokens
					result.Messages = compressedMessages
					result.PromptTokens = newConsumedTokens // æ›´æ–°ç´¯ç§¯ token æ•°
					subAgentLog("INFO", "ğŸ’¾ SubAgent compression successful: %d->%d messages, tokens: %d->%d",
						messageCount, len(compressedMessages), currentTokens, newCurrentTokens)

					// å‘é€å‹ç¼©æˆåŠŸçš„æµå¼é€šçŸ¥
					if isStreaming {
						streamCallback(StreamChunk{
							Type:     "subagent_compression",
							Content:  fmt.Sprintf("ğŸ’¾ SubAgent compressed %d messages to %d (saved %d tokens)",
								messageCount, len(compressedMessages), currentTokens-newCurrentTokens),
							Metadata: map[string]any{
								"iteration":        iteration,
								"compress_reason":  compressReason,
								"original_messages": messageCount,
								"compressed_messages": len(compressedMessages),
								"tokens_saved":     currentTokens - newCurrentTokens,
							},
						})
					}
				} else {
					// å‹ç¼©å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ
					subAgentLog("WARN", "âš ï¸ SubAgent compression failed at iteration %d, continuing with original messages", iteration)
				}
			} else {
				subAgentLog("DEBUG", "ğŸ’¾ SubAgent skipping compression at iteration %d: %d messages, %d tokens (below thresholds)",
					iteration, messageCount, currentTokens)
			}
		}

		// SubAgent ä¸“ç”¨ï¼šåœ¨ LLM è°ƒç”¨å‰æ£€æŸ¥æ˜¯å¦éœ€è¦ç´§æ€¥å‹ç¼©
		if rc.messageProcessor != nil {
			// ä¼°ç®—å½“å‰æ¶ˆæ¯çš„ token æ•°
			estimatedTokens := rc.estimateMessageTokens(result.Messages)
			maxTokensLimit := execCtx.Config.MaxTokens
			if maxTokensLimit <= 0 {
				maxTokensLimit = 8000 // é»˜è®¤é™åˆ¶
			}

			// å¦‚æœé¢„è®¡ token æ•°è¶…è¿‡ 80% çš„é™åˆ¶ï¼Œè¿›è¡Œç´§æ€¥å‹ç¼©
			if estimatedTokens > int(float64(maxTokensLimit)*0.8) {
				subAgentLog("WARN", "âš ï¸ SubAgent emergency compression triggered: %d tokens (80%% of %d limit)", estimatedTokens, maxTokensLimit)

				// æ‰§è¡Œç´§æ€¥å‹ç¼©
				totalTokensUsed := result.PromptTokens + result.CompletionTokens
				compressedMessages, newConsumedTokens, newCurrentTokens := rc.compressMessagesWithFallback(ctx, result.Messages, totalTokensUsed, result.CurrentMessageTokens, iteration)

				if compressedMessages != nil && len(compressedMessages) < len(result.Messages) {
					result.Messages = compressedMessages
					result.PromptTokens = newConsumedTokens
					result.CurrentMessageTokens = newCurrentTokens
					subAgentLog("INFO", "âœ… SubAgent emergency compression successful: %d->%d messages", len(result.Messages), len(compressedMessages))

					if isStreaming {
						streamCallback(StreamChunk{
							Type:     "emergency_compression",
							Content:  fmt.Sprintf("âš¡ Emergency compression: %d->%d messages to avoid context limit", len(result.Messages), len(compressedMessages)),
							Metadata: map[string]any{"iteration": iteration, "reason": "approaching_context_limit"},
						})
					}
				}
			}
		}

		// æ„å»ºLLMè¯·æ±‚
		request := &llm.ChatRequest{
			Messages:   result.Messages,
			ModelType:  llm.BasicModel,
			Tools:      execCtx.Tools,
			ToolChoice: "auto",
			Config:     execCtx.Config,
			MaxTokens:  execCtx.Config.MaxTokens,
		}

		// è·å–LLMå®ä¾‹
		subAgentLog("DEBUG", "ğŸ¤– Getting LLM instance for iteration %d", iteration)
		client, err := llm.GetLLMInstance(llm.BasicModel)
		if err != nil {
			subAgentLog("ERROR", "Failed to get LLM instance at iteration %d: %v", iteration, err)
			if isStreaming {
				streamCallback(StreamChunk{Type: "error", Content: fmt.Sprintf("âŒ LLM initialization failed: %v", err)})
			}
			return nil, fmt.Errorf("LLM initialization failed at iteration %d: %w", iteration, err)
		}

		// éªŒè¯è¯·æ±‚
		if err := rc.llmHandler.validateLLMRequest(request); err != nil {
			subAgentLog("ERROR", "Invalid LLM request at iteration %d: %v", iteration, err)
			if isStreaming {
				streamCallback(StreamChunk{Type: "error", Content: fmt.Sprintf("âŒ Invalid request: %v", err)})
			}
			return nil, fmt.Errorf("invalid LLM request at iteration %d: %w", iteration, err)
		}

		// æ‰§è¡ŒLLMè°ƒç”¨
		subAgentLog("INFO", "ğŸ¤– Calling LLM for iteration %d...", iteration)
		response, err := rc.llmHandler.callLLMWithRetry(ctx, client, request, 6)
		if err != nil {
			subAgentLog("ERROR", "LLM call failed at iteration %d: %v", iteration, err)
			if isStreaming {
				streamCallback(StreamChunk{Type: "error", Content: fmt.Sprintf("âŒ LLM call failed: %v", err)})
			}
			return nil, fmt.Errorf("LLM call failed at iteration %d: %w", iteration, err)
		}
		subAgentLog("DEBUG", "ğŸ¤– LLM call completed for iteration %d", iteration)

		// éªŒè¯å“åº”
		if response == nil || len(response.Choices) == 0 {
			subAgentLog("ERROR", "Invalid response at iteration %d", iteration)
			if isStreaming {
				streamCallback(StreamChunk{Type: "error", Content: "âŒ Invalid response from LLM"})
			}
			return nil, fmt.Errorf("invalid response at iteration %d", iteration)
		}

		choice := response.Choices[0]
		step.Thought = strings.TrimSpace(choice.Message.Content)

		// å¤„ç†tokenä½¿ç”¨æƒ…å†µ
		usage := response.GetUsage()
		tokensUsed := usage.GetTotalTokens()
		promptTokens := usage.GetPromptTokens()
		completionTokens := usage.GetCompletionTokens()

		result.TokensUsed += tokensUsed
		result.PromptTokens += promptTokens
		result.CompletionTokens += completionTokens
		result.CurrentMessageTokens += promptTokens // å½“å‰æ¶ˆæ¯tokenæ•°ç´¯åŠ 
		step.TokensUsed = tokensUsed

		// å‘é€tokenä½¿ç”¨æƒ…å†µ
		if isStreaming && tokensUsed > 0 {
			streamCallback(StreamChunk{
				Type:             "token_usage",
				Content:          fmt.Sprintf("Tokens used: %d (prompt: %d, completion: %d)", tokensUsed, promptTokens, completionTokens),
				TokensUsed:       tokensUsed,
				TotalTokensUsed:  result.TokensUsed,
				PromptTokens:     promptTokens,
				CompletionTokens: completionTokens,
				Metadata:         map[string]any{"iteration": iteration, "phase": "core_token_accounting"},
			})
		}

		// å‘é€æ€è€ƒç»“æœ
		if len(choice.Message.Content) > 0 && len(choice.Message.ToolCalls) > 0 {
			if isStreaming {
				streamCallback(StreamChunk{
					Type:     "thinking_result",
					Content:  choice.Message.Content,
					Metadata: map[string]any{"iteration": iteration, "phase": "core_thinking"},
				})
			}
		}

		// æ·»åŠ assistantæ¶ˆæ¯åˆ°å¯¹è¯å†å²
		if len(choice.Message.Content) > 0 || len(choice.Message.ToolCalls) > 0 {
			result.Messages = append(result.Messages, choice.Message)
		}

		// è§£æå·¥å…·è°ƒç”¨
		subAgentLog("DEBUG", "ğŸ” Parsing tool calls from LLM response at iteration %d", iteration)
		toolCalls := rc.agent.parseToolCalls(&choice.Message)
		subAgentLog("INFO", "ğŸ” Parsed %d tool calls", len(toolCalls))

		if len(toolCalls) > 0 {
			step.Action = "tool_execution"
			step.ToolCall = toolCalls

			subAgentLogger.Info("ğŸ”§ Executing %d tool calls at iteration %d", len(toolCalls), iteration)

			// Check for multiple subagent calls - use parallel execution if detected
			subagentCalls := rc.filterSubAgentCalls(toolCalls)
			
			var toolResult []*types.ReactToolResult
			
			if len(subagentCalls) > 1 {
				subAgentLog("INFO", "ğŸš€ Detected %d subagent calls - executing in parallel", len(subagentCalls))
				toolResult = rc.executeSubAgentsInParallel(ctx, toolCalls, subagentCalls, streamCallback)
			} else {
				// ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·æ‰§è¡Œç³»ç»Ÿè¿›è¡Œä¸²è¡Œæ‰§è¡Œ
				toolExecutor := utils.NewToolExecutor("SUB-AGENT")
				displayFormatter := utils.NewToolDisplayFormatter() // Default green color

				// è½¬æ¢å›è°ƒå‡½æ•°ç±»å‹
				var utilsCallback utils.StreamCallback
				if streamCallback != nil {
					utilsCallback = func(chunk utils.StreamChunk) {
						// è½¬æ¢ utils.StreamChunk åˆ° agent.StreamChunk
						agentChunk := StreamChunk{
							Type:             chunk.Type,
							Content:          chunk.Content,
							Complete:         chunk.Complete,
							Metadata:         chunk.Metadata,
							TokensUsed:       chunk.TokensUsed,
							TotalTokensUsed:  chunk.TotalTokensUsed,
							PromptTokens:     chunk.PromptTokens,
							CompletionTokens: chunk.CompletionTokens,
						}
						streamCallback(agentChunk)
					}
				}

				toolResult = toolExecutor.ExecuteSerialToolsWithRecovery(
					ctx,
					toolCalls,
					rc.executeToolDirect,
					utilsCallback,
					displayFormatter.Format,
				)
			}

			step.Result = toolResult
			subAgentLogger.Info("ğŸ”§ Tool execution completed with %d results", len(toolResult))
			subAgentLogger.Debug("ğŸ”§ Tool execution completed with %+v", toolResult)

			// æ„å»ºå·¥å…·æ¶ˆæ¯
			if toolResult != nil {
				isGemini := strings.Contains(request.Config.BaseURL, "googleapis")
				toolMessages := rc.toolHandler.buildToolMessages(toolResult, isGemini)

				result.Messages = append(result.Messages, toolMessages...)

				step.Observation = rc.toolHandler.generateObservation(toolResult)
			}
			// æ·»åŠ ä»»åŠ¡è¾“å…¥ï¼Œé‡å¤æé†’ç›®æ ‡
			result.Messages = append(result.Messages, llm.Message{
				Role:    "user",
				Content: execCtx.Task,
			})
		} else {
			// æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›æœ€ç»ˆç­”æ¡ˆ
			finalAnswer := choice.Message.Content
			step.Action = "direct_answer"
			step.Observation = finalAnswer
			step.Duration = time.Since(step.Timestamp)

			subAgentLog("INFO", "âœ… Task completed at iteration %d with direct answer", iteration)
			result.Answer = finalAnswer
			result.Success = true
			result.Confidence = 0.8
			result.History = append(result.History, step)

			if isStreaming {
				streamCallback(StreamChunk{
					Type:     "final_answer",
					Content:  finalAnswer,
					Metadata: map[string]any{"iteration": iteration, "phase": "core_final_answer"},
				})
			}
			return result, nil
		}

		step.Duration = time.Since(step.Timestamp)
		result.History = append(result.History, step)
	}

	// è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
	subAgentLog("WARN", "Maximum iterations (%d) reached", maxIterations)
	if isStreaming {
		streamCallback(StreamChunk{
			Type:     "max_iterations",
			Content:  fmt.Sprintf("âš ï¸ Core execution reached maximum iterations (%d)", maxIterations),
			Metadata: map[string]any{"max_iterations": maxIterations},
		})
	}

	result.Answer = "Maximum iterations reached without completion"
	result.Success = false
	result.Confidence = 0.5
	return result, nil
}

// NewTaskExecutionContext - åˆ›å»ºä»»åŠ¡æ‰§è¡Œä¸Šä¸‹æ–‡çš„ä¾¿æ·å‡½æ•°
func (rc *ReactCore) NewTaskExecutionContext(ctx context.Context, task string, systemPrompt string, maxIter int) *TaskExecutionContext {
	taskID := generateTaskID()
	taskCtx := types.NewReactTaskContext(taskID, task)

	// æ„å»ºåˆå§‹æ¶ˆæ¯åˆ—è¡¨
	messages := []llm.Message{
		{
			Role:    "system",
			Content: systemPrompt,
		},
		{
			Role:    "user",
			Content: task,
		},
	}

	// æ„å»ºå·¥å…·å®šä¹‰
	tools := rc.toolHandler.buildToolDefinitions(ctx)

	return &TaskExecutionContext{
		TaskID:         taskID,
		Task:           task,
		Messages:       messages,
		TaskCtx:        taskCtx,
		Tools:          tools,
		Config:         rc.agent.llmConfig,
		MaxIter:        maxIter,
		Session:        nil,                     // ç”±è°ƒç”¨è€…åœ¨éœ€è¦æ—¶è®¾ç½®
		SessionManager: rc.agent.sessionManager, // ä½¿ç”¨ReactCoreæ‰€å±çš„session manager
	}
}

// ========== Sub-Agent Architecture Support ==========

// SubAgentInterface - Sub-agentæ¥å£ï¼Œå®šä¹‰sub-agentçš„æ ¸å¿ƒèƒ½åŠ›
type SubAgentInterface interface {
	// ExecuteTask - æ‰§è¡Œç‹¬ç«‹ä»»åŠ¡ï¼Œè¿”å›å®ŒæˆçŠ¶æ€å’Œç»“æœ
	ExecuteTask(ctx context.Context, task string) (*SubAgentResult, error)

	// ExecuteTaskWithStream - æ‰§è¡Œç‹¬ç«‹ä»»åŠ¡ï¼Œæ”¯æŒæµå¼å›è°ƒä»¥æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¿‡ç¨‹
	ExecuteTaskWithStream(ctx context.Context, task string, streamCallback StreamCallback) (*SubAgentResult, error)

	// GetSessionID - è·å–sub-agentçš„session ID
	GetSessionID() string

	// GetConfig - è·å–sub-agenté…ç½®
	GetConfig() *SubAgentConfig
}

// SubAgentConfig - Sub-agenté…ç½®
type SubAgentConfig struct {
	SessionID     string   // å­ä¼šè¯ID
	MaxIterations int      // æœ€å¤§è¿­ä»£æ¬¡æ•°
	Tools         []string // å…è®¸ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
	ContextCache  bool     // æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡ç¼“å­˜
}

// SubAgentResult - Sub-agentæ‰§è¡Œç»“æœ
type SubAgentResult struct {
	Success       bool   `json:"success"`
	TaskCompleted bool   `json:"task_completed"`
	Result        string `json:"result"`                  // ä»»åŠ¡ç»“æœå†…å®¹
	MaterialPath  string `json:"material_path"`           // ç‰©æ–™åœ°å€ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ï¼‰
	SessionID     string `json:"session_id"`              // å­ä¼šè¯ID
	TokensUsed    int    `json:"tokens_used"`             // ä½¿ç”¨çš„tokenæ•°
	Duration      int64  `json:"duration_ms"`             // æ‰§è¡Œæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
	ErrorMessage  string `json:"error_message,omitempty"` // é”™è¯¯ä¿¡æ¯
}

// SubAgent - Sub-agentçš„å…·ä½“å®ç°
type SubAgent struct {
	config         *SubAgentConfig
	reactCore      *ReactCore
	sessionManager *session.Manager // ç‹¬ç«‹çš„session manager
	sessionID      string
}

// NewSubAgent - åˆ›å»ºæ–°çš„sub-agentå®ä¾‹
func NewSubAgent(parentCore *ReactCore, config *SubAgentConfig) (*SubAgent, error) {
	// æ·»åŠ å…¨é¢çš„nilæ£€æŸ¥
	if parentCore == nil {
		return nil, fmt.Errorf("parentCore cannot be nil")
	}
	if parentCore.agent == nil {
		return nil, fmt.Errorf("parentCore.agent cannot be nil")
	}
	if parentCore.agent.llm == nil {
		return nil, fmt.Errorf("parentCore.agent.llm cannot be nil")
	}
	if parentCore.agent.configManager == nil {
		return nil, fmt.Errorf("parentCore.agent.configManager cannot be nil")
	}
	if parentCore.agent.llmConfig == nil {
		return nil, fmt.Errorf("parentCore.agent.llmConfig cannot be nil")
	}
	if config == nil {
		return nil, fmt.Errorf("config cannot be nil")
	}

	if config.SessionID == "" {
		config.SessionID = fmt.Sprintf("sub_%s", generateTaskID())
	}

	subAgentLog("INFO", "Creating new sub-agent with session ID: %s", config.SessionID)

	// åˆ›å»ºç‹¬ç«‹çš„session managerï¼Œé¿å…ä¸ä¸»agentå†²çª
	subSessionManager, err := session.NewManager()
	if err != nil {
		subAgentLog("ERROR", "Failed to create session manager: %v", err)
		return nil, fmt.Errorf("failed to create sub-agent session manager: %w", err)
	}

	// åˆ›å»ºç‹¬ç«‹çš„å·¥å…·æ³¨å†Œå™¨ï¼Œä½¿ç”¨sub-agentæ¨¡å¼é˜²æ­¢é€’å½’
	subToolRegistry := NewToolRegistryWithSubAgentMode(parentCore.agent.configManager, subSessionManager, true)

	agent := &ReactAgent{
		llm:            parentCore.agent.llm,
		configManager:  parentCore.agent.configManager,
		sessionManager: subSessionManager,
		toolRegistry:   subToolRegistry,
		config:         types.NewReactConfig(),
		llmConfig:      parentCore.agent.llmConfig,
		promptBuilder:  NewLightPromptBuilder(), // æ·»åŠ ç¼ºå¤±çš„promptBuilder
		messageQueue:   NewMessageQueue(),       // åˆå§‹åŒ–MessageQueueé˜²æ­¢nil pointer
	}
	// åˆ›å»ºç‹¬ç«‹çš„ReactCoreå®ä¾‹ï¼Œé¿å…sessionçŠ¶æ€æ±¡æŸ“
	subReactCore := NewReactCore(agent, subToolRegistry)
	if subReactCore == nil {
		subAgentLog("ERROR", "Failed to create ReactCore for subagent")
		return nil, fmt.Errorf("failed to create ReactCore for subagent")
	}

	subAgentLog("INFO", "Sub-agent initialized successfully with %d tools", len(subToolRegistry.ListTools(context.Background())))

	return &SubAgent{
		config:         config,
		reactCore:      subReactCore,
		sessionManager: subSessionManager,
		sessionID:      config.SessionID,
	}, nil
}

// ExecuteTask - å®ç°SubAgentInterface.ExecuteTaskï¼Œæ”¯æŒæµå¼å›è°ƒ
func (sa *SubAgent) ExecuteTask(ctx context.Context, task string, streamCallback StreamCallback) (result *SubAgentResult, err error) {
	startTime := time.Now()

	// Comprehensive panic recovery for subagent execution
	defer func() {
		if r := recover(); r != nil {
			subAgentLog("ERROR", "Sub-agent task execution panicked: %v", r)
			// Create safe result on panic
			result = &SubAgentResult{
				Success:       false,
				TaskCompleted: false,
				Result:        "Task execution was interrupted by system panic but recovered safely",
				SessionID:     sa.sessionID,
				Duration:      time.Since(startTime).Milliseconds(),
				ErrorMessage:  fmt.Sprintf("panic during execution: %v", r),
			}
			err = fmt.Errorf("subagent execution panicked: %v", r)

			if streamCallback != nil {
				streamCallback(StreamChunk{
					Type:     "sub_agent_panic_recovery",
					Content:  fmt.Sprintf("âš ï¸ Sub-agent recovered from panic: %v", r),
					Metadata: map[string]any{"sub_agent_id": sa.sessionID, "panic_value": fmt.Sprintf("%v", r)},
				})
			}
		}
	}()

	subAgentLog("INFO", "ğŸš€ Starting sub-agent task execution with stream callback")
	subAgentLog("INFO", "ğŸ“‹ Task: %s", task)
	subAgentLog("INFO", "ğŸ†” Session ID: %s", sa.sessionID)

	// ä¸ºsub-agentåˆ›å»ºç‹¬ç«‹çš„sessionï¼Œé¿å…ä¸ä¸»agentæ··æ·†
	subAgentLog("DEBUG", "ğŸ“ Creating independent session for sub-agent")
	subSession, err := sa.sessionManager.StartSession(sa.sessionID)
	if err != nil {
		subAgentLog("ERROR", "Failed to start session: %v", err)
		return &SubAgentResult{
			Success:       false,
			TaskCompleted: false,
			Result:        "",
			SessionID:     sa.sessionID,
			Duration:      time.Since(startTime).Milliseconds(),
			ErrorMessage:  fmt.Sprintf("failed to start sub-agent session: %v", err),
		}, err
	}
	subAgentLog("DEBUG", "ğŸ“ Session created successfully")

	// å‡†å¤‡ç³»ç»Ÿæç¤º
	systemPrompt := sa.buildDefaultSystemPrompt()

	// åˆ›å»ºç‹¬ç«‹çš„ä»»åŠ¡æ‰§è¡Œä¸Šä¸‹æ–‡
	execCtx := sa.reactCore.NewTaskExecutionContext(ctx, task, systemPrompt, sa.config.MaxIterations)

	// è®¾ç½®sub-agentä¸“ç”¨çš„sessionå’Œsession manager
	execCtx.Session = subSession
	execCtx.SessionManager = sa.sessionManager

	// å¦‚æœæœ‰å·¥å…·é™åˆ¶ï¼Œè¿‡æ»¤å·¥å…·åˆ—è¡¨
	if len(sa.config.Tools) > 0 {
		execCtx.Tools = sa.filterTools(execCtx.Tools)
	}

	// å‘é€å­ä»£ç†å¼€å§‹ä¿¡å·
	if streamCallback != nil {
		streamCallback(StreamChunk{
			Type:     "sub_agent_start",
			Content:  fmt.Sprintf("ğŸ¤– Sub-agent starting task: %s", task),
			Metadata: map[string]any{"sub_agent_id": sa.sessionID, "task": task},
		})
	}

	// æ‰§è¡Œæ ¸å¿ƒä»»åŠ¡ï¼Œä¼ å…¥æµå¼å›è°ƒ with robust error handling
	subAgentLog("INFO", "âš¡ Executing core task with max %d iterations and stream callback", sa.config.MaxIterations)
	coreResult, err := sa.reactCore.ExecuteTaskCore(ctx, execCtx, streamCallback)
	if err != nil {
		// Enhanced error handling for context limit and other API errors
		if isContextLimitError(err) {
			subAgentLog("WARN", "âš ï¸ Core task hit context limits, attempting graceful degradation: %v", err)
			if streamCallback != nil {
				streamCallback(StreamChunk{
					Type:     "context_limit_warning",
					Content:  "âš ï¸ Task hit context limits but recovered with partial results",
					Metadata: map[string]any{"sub_agent_id": sa.sessionID, "error_type": "context_limit"},
				})
			}
			// Return partial results instead of complete failure
			return &SubAgentResult{
				Success:       false,
				TaskCompleted: false,
				Result:        "Task partially completed before hitting context limits",
				SessionID:     sa.sessionID,
				Duration:      time.Since(startTime).Milliseconds(),
				ErrorMessage:  fmt.Sprintf("context limit reached: %v", err),
			}, nil // Don't return error, let caller handle gracefully
		}

		subAgentLog("ERROR", "âŒ Core task execution failed: %v", err)
		if streamCallback != nil {
			streamCallback(StreamChunk{
				Type:     "sub_agent_error",
				Content:  fmt.Sprintf("âŒ Sub-agent execution failed: %v", err),
				Metadata: map[string]any{"sub_agent_id": sa.sessionID, "error": err.Error()},
			})
		}
		return &SubAgentResult{
			Success:       false,
			TaskCompleted: false,
			Result:        "",
			SessionID:     sa.sessionID,
			Duration:      time.Since(startTime).Milliseconds(),
			ErrorMessage:  err.Error(),
		}, err
	}
	subAgentLog("DEBUG", "âš¡ Core task execution completed")

	// æ„å»ºsub-agentç»“æœ
	subResult := &SubAgentResult{
		Success:       coreResult.Success,
		TaskCompleted: coreResult.Success,
		Result:        coreResult.Answer,
		SessionID:     sa.sessionID,
		TokensUsed:    coreResult.TokensUsed,
		Duration:      time.Since(startTime).Milliseconds(),
	}

	// å‘é€å­ä»£ç†å®Œæˆä¿¡å·
	if streamCallback != nil {
		streamCallback(StreamChunk{
			Type:    "sub_agent_complete",
			Content: fmt.Sprintf("âœ… Sub-agent completed: %s", subResult.Result),
			Metadata: map[string]any{
				"sub_agent_id":   sa.sessionID,
				"success":        subResult.Success,
				"task_completed": subResult.TaskCompleted,
				"tokens_used":    subResult.TokensUsed,
				"duration":       subResult.Duration,
			},
		})
	}

	// å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯
	if !coreResult.Success {
		subResult.ErrorMessage = "Task execution did not complete successfully"
		subAgentLog("WARN", "Task execution unsuccessful after %dms", subResult.Duration)
	} else {
		subAgentLog("INFO", "Task completed successfully in %dms, tokens used: %d",
			subResult.Duration, subResult.TokensUsed)
	}

	return subResult, nil
}

// GetSessionID - å®ç°SubAgentInterface.GetSessionID
func (sa *SubAgent) GetSessionID() string {
	return sa.sessionID
}

// GetConfig - å®ç°SubAgentInterface.GetConfig
func (sa *SubAgent) GetConfig() *SubAgentConfig {
	return sa.config
}

// buildDefaultSystemPrompt - æ„å»ºé»˜è®¤çš„sub-agentç³»ç»Ÿæç¤ºï¼ˆåŸºäºä¸»agentä½†ç§»é™¤é€’å½’å­ä»£ç†èƒ½åŠ›ï¼‰
func (sa *SubAgent) buildDefaultSystemPrompt() string {
	return `You are a specialized sub-agent with coding assistant capabilities and product thinking mindset. You investigate problems before writing code and create practical, testable solutions.

## Context
- **Working as Sub-Agent**: You are executing a specific task assigned by the main agent
- **Task Focus**: Complete the assigned task efficiently and report results clearly
- **No Sub-Agents**: You cannot create or launch other sub-agents (this capability is disabled)

# Core Principles
- **Act Immediately**: Start working without asking questions
- **Test Everything**: Every task must have verifiable completion criteria
- **Investigate First**: Research user needs and available tools
- **Use Tools Together**: Run multiple tools at once when possible
- **Keep Answers Short**: 1-4 lines unless user wants more detail
- **Write Good Code**: Focus on security, speed, and easy maintenance
- **Large Files**: Split files >10000 chars into segments (multiple file_edit calls)

# Research Strategy

**INVESTIGATE FIRST** (before any coding):
- **User Workflow**: How will people actually use this?
- **Industry Patterns**: What do successful projects do?
- **Available Tools**: What libraries and frameworks exist?
- **Competition**: How do other products solve this?
- **Testing Requirements**: How will we verify this works?

**DESIGN CRITERIA** (every feature must meet):
- **User Value**: Solves a real problem
- **Business Goals**: Helps achieve objectives  
- **Testability**: Can be verified/measured
- **Scalability**: Works with more users
- **Maintainability**: Easy to maintain and extend

# Tool Usage & File Handling

**PARALLEL EXECUTION**: Run multiple tools together:
` + "`" + `
// Research: file_read(docs/) + web_search("patterns") + grep_search("examples")
// Verify: file_read(src/) + file_list() + bash("test command")
` + "`" + `

**LARGE FILES (>10000 chars)**: Use segmented writing:
` + "`" + `
1. Plan: Break into logical 2000-5000 char segments
2. Write: file_edit(path, "", segment1)           // Create with first part
3. Append: file_edit(path, marker1, segment2)     // Add second part  
4. Continue: file_edit(path, marker2, segment3)   // Add remaining parts
5. Test: file_read(path) + validation commands
` + "`" + `

**SEGMENT BOUNDARIES** (for appending):
- Functions: ` + "`" + `}\n\n` + "`" + ` | Classes: ` + "`" + `}\n\n` + "`" + ` | Sections: unique closing tags

# WORKFLOW

## Sub-Agent Process (focused task execution):

1. **UNDERSTAND**: Analyze the assigned task and its requirements
2. **RESEARCH**: Investigate domain + technical + business context if needed
3. **PLAN**: Design solution with testing criteria + user value
4. **TODO**: Break into specific, testable tasks (if complex)
5. **EXECUTE**: Build + test each task immediately
6. **VERIFY**: Confirm complete solution works
7. **REPORT**: Provide clear results to the main agent

## Task Testing Requirements:

**EVERY TASK** must include verification step:
- **Code**: Run/compile + check functionality
- **Files**: Read result + verify content/structure
- **Config**: Test settings work correctly
- **Docs**: Check readability + accuracy
- **Large Files (>10000 chars)**: Use segmented writing + final verification

## TODO Standards:
- **Specific**: Clear, actionable with test criteria
- **Testable**: Each task has verification method
- **Sequential**: Complete + test before next task
- **Complete**: Mark done only after successful verification

# Communication & Examples

**STYLE**: Direct answers, 1-4 lines max. Avoid "Here is...", "Let me...", "I'll help..."

**SIMPLE TASKS**:
` + "`" + `
User: 2 + 2
Assistant: 4

User: Hello  
Assistant: Hi! What specific task should I complete?
` + "`" + `

**COMPLEX TASKS** (with testing):
` + "`" + `
User: Build authentication system
Assistant: [web_search("auth best practices") + file_read(existing_auth) + grep_search("security")]
[todo_update: 1.Research patterns+test requirements 2.Design flow+security tests 3.Implement JWT 4.Add OAuth 5.Test auth flow 6.Test security 7.Deploy+verify]
JWT + OAuth2 recommended. Testing plan included...
` + "`" + `

# Sub-Agent Specific Guidelines

- **Focus on assigned task**: Complete the specific task given by the main agent
- **Report results clearly**: Provide concrete, actionable results
- **No recursive sub-agents**: You cannot create additional sub-agents
- **Work autonomously**: Use all available tools except sub-agent creation
- **Be efficient**: Complete tasks quickly and thoroughly
- **Test thoroughly**: Verify all work before reporting completion

You should work autonomously within your task scope and provide concrete results that the main agent can use.`
}

// estimateMessageTokens - å¿«é€Ÿä¼°ç®—æ¶ˆæ¯çš„ token æ•°é‡
func (rc *ReactCore) estimateMessageTokens(messages []llm.Message) int {
	totalTokens := 0
	for _, msg := range messages {
		// ç®€å•çš„å­—ç¬¦æ•°ä¼°ç®—ï¼šé€šå¸¸ 1 token â‰ˆ 4 characters
		contentLength := len(msg.Content)
		estimatedTokens := contentLength / 4

		// ä¸ºå·¥å…·è°ƒç”¨æ·»åŠ é¢å¤–çš„ token ä¼°ç®—
		if len(msg.ToolCalls) > 0 {
			for _, tc := range msg.ToolCalls {
				estimatedTokens += len(tc.Function.Name)/4 + len(tc.Function.Arguments)/4 + 10 // é¢å¤–å¼€é”€
			}
		}

		totalTokens += estimatedTokens
	}

	// æ·»åŠ æ¶ˆæ¯ç»“æ„å¼€é”€
	totalTokens += len(messages) * 10 // æ¯æ¡æ¶ˆæ¯å¤§çº¦ 10 token çš„ç»“æ„å¼€é”€

	return totalTokens
}

// compressMessagesWithFallback - SubAgent ä¸“ç”¨çš„æ¶ˆæ¯å‹ç¼©ï¼Œå¸¦æœ‰é™çº§ç­–ç•¥
func (rc *ReactCore) compressMessagesWithFallback(ctx context.Context, messages []llm.Message, consumedTokens, currentTokens, iteration int) ([]llm.Message, int, int) {
	// é¦–å…ˆå°è¯•æ­£å¸¸å‹ç¼©
	compressedMessages, newConsumedTokens, newCurrentTokens := rc.messageProcessor.CompressMessages(ctx, messages, consumedTokens, currentTokens)

	// æ£€æŸ¥å‹ç¼©æ˜¯å¦æˆåŠŸï¼ˆå‹ç¼©åæ¶ˆæ¯æ•°é‡åº”è¯¥å‡å°‘ï¼‰
	if len(compressedMessages) > 0 && len(compressedMessages) < len(messages) {
		subAgentLog("DEBUG", "âœ… SubAgent compression successful via normal method")
		return compressedMessages, newConsumedTokens, newCurrentTokens
	}

	// å¦‚æœæ­£å¸¸å‹ç¼©å¤±è´¥ï¼Œå°è¯•ç®€å•çš„å†å²è£å‰ªç­–ç•¥
	subAgentLog("WARN", "âš ï¸ Normal compression failed, trying fallback message truncation")

	if len(messages) <= 3 {
		// æ¶ˆæ¯å¤ªå°‘ï¼Œæ— æ³•è£å‰ª
		subAgentLog("WARN", "Too few messages for fallback compression, keeping original")
		return messages, consumedTokens, currentTokens
	}

	// ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„æ¶ˆæ¯ï¼Œåˆ é™¤ä¸­é—´çš„æ¶ˆæ¯
	fallbackMessages := make([]llm.Message, 0, len(messages))

	// ä¿ç•™å‰2æ¡ç³»ç»Ÿæ¶ˆæ¯
	systemMsgCount := 0
	for i, msg := range messages {
		if msg.Role == "system" && systemMsgCount < 2 {
			fallbackMessages = append(fallbackMessages, msg)
			systemMsgCount++
		} else if msg.Role != "system" {
			// åªä¿ç•™æœ€å3æ¡éç³»ç»Ÿæ¶ˆæ¯
			if i >= len(messages)-3 {
				fallbackMessages = append(fallbackMessages, msg)
			}
		}
	}

	// æ·»åŠ ä¸€æ¡è¯´æ˜æ¶ˆæ¯
	fallbackMessages = append(fallbackMessages, llm.Message{
		Role:    "assistant",
		Content: fmt.Sprintf("ğŸ“ [SubAgent Note: Message history was truncated at iteration %d to manage context length. Previous conversation context may be lost.]", iteration),
	})

	subAgentLog("INFO", "ğŸ“ SubAgent fallback compression: %d->%d messages", len(messages), len(fallbackMessages))

	// é‡æ–°è®¡ç®— token æ•°ï¼ˆç®€å•ä¼°ç®—ï¼‰
	newCurrentTokens = currentTokens / 3 // ç²—ç•¥ä¼°ç®—å‹ç¼©åçš„ token æ•°

	return fallbackMessages, consumedTokens + currentTokens/2, newCurrentTokens
}

// isSubAgentContext - Check if execution context is for a SubAgent
func isSubAgentContext(execCtx *TaskExecutionContext) bool {
	if execCtx == nil || execCtx.TaskID == "" {
		return false
	}
	// SubAgent TaskIDs typically start with "sub_" prefix
	return strings.HasPrefix(execCtx.TaskID, "sub_") ||
		(execCtx.Session != nil && strings.Contains(execCtx.Session.ID, "sub"))
}


// filterTools - æ ¹æ®é…ç½®è¿‡æ»¤å¯ç”¨å·¥å…·
func (sa *SubAgent) filterTools(allTools []llm.Tool) []llm.Tool {
	var filteredTools []llm.Tool

	// å§‹ç»ˆè¿‡æ»¤æ‰sub_agentå·¥å…·ï¼Œé˜²æ­¢æ— é™é€’å½’
	for _, tool := range allTools {
		if tool.Function.Name == "sub_agent" {
			subAgentLog("DEBUG", "Filtered out sub_agent tool to prevent recursion")
			continue
		}
		filteredTools = append(filteredTools, tool)
	}

	// å¦‚æœæŒ‡å®šäº†å…è®¸çš„å·¥å…·åˆ—è¡¨ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤
	if len(sa.config.Tools) > 0 {
		allowedTools := make(map[string]bool)
		for _, toolName := range sa.config.Tools {
			// ç¡®ä¿sub_agentä¸åœ¨å…è®¸åˆ—è¡¨ä¸­
			if toolName != "sub_agent" {
				allowedTools[toolName] = true
			}
		}

		var finalTools []llm.Tool
		for _, tool := range filteredTools {
			if allowedTools[tool.Function.Name] {
				finalTools = append(finalTools, tool)
			}
		}
		return finalTools
	}

	return filteredTools
}

// ========== Tool Integration for Sub-Agent ==========

// ExecuteSubAgentTask - ä½œä¸ºå·¥å…·è°ƒç”¨çš„sub-agentåŒ…è£…å™¨
// è¿™ä¸ªå‡½æ•°å¯ä»¥è¢«æ³¨å†Œä¸ºä¸€ä¸ªå·¥å…·ï¼Œä¾›ä¸»agentè°ƒç”¨
func (rc *ReactCore) ExecuteSubAgentTask(ctx context.Context, args map[string]interface{}) (interface{}, error) {
	// è§£æå‚æ•°
	task, ok := args["task"].(string)
	if !ok {
		return nil, fmt.Errorf("task parameter is required and must be a string")
	}

	// å¯é€‰å‚æ•°
	maxIter := 50 // é»˜è®¤å€¼
	if iter, exists := args["max_iterations"]; exists {
		if iterInt, ok := iter.(int); ok {
			maxIter = iterInt
		}
	}

	var allowedTools []string
	if tools, exists := args["allowed_tools"]; exists {
		if toolsSlice, ok := tools.([]interface{}); ok {
			for _, tool := range toolsSlice {
				if toolStr, ok := tool.(string); ok {
					allowedTools = append(allowedTools, toolStr)
				}
			}
		}
	}

	// åˆ›å»ºsub-agenté…ç½®
	config := &SubAgentConfig{
		MaxIterations: maxIter,
		Tools:         allowedTools,
		ContextCache:  true, // é»˜è®¤å¯ç”¨ä¸Šä¸‹æ–‡ç¼“å­˜
	}

	// åˆ›å»ºå¹¶æ‰§è¡Œsub-agent
	subAgent, err := NewSubAgent(rc, config)
	if err != nil {
		return nil, fmt.Errorf("failed to create sub-agent: %w", err)
	}

	// ä½¿ç”¨å®‰å…¨çš„å›è°ƒå‡½æ•° - å¦‚æœReactCoreçš„streamCallbackä¸ºnilï¼Œä½¿ç”¨nil
	// ExecuteTaskå†…éƒ¨ä¼šå¤„ç†nil streamCallbackçš„æƒ…å†µ
	var safeCallback StreamCallback
	if rc.streamCallback != nil {
		safeCallback = rc.streamCallback
	}

	return subAgent.ExecuteTask(ctx, task, safeCallback)
}
